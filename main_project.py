from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
import os
from dotenv import load_dotenv

load_dotenv()
# print(os.getenv("GOOGLE_API_KEY")) # GÃ¼venlik iÃ§in kapattÄ±m

# AYARLAR VE DOSYA YOLLARI
PDF_YOLU = "data/NLP13.pdf"
DB_YOLU = "./chroma_db_deposu2"

# 1. VERÄ° YÃœKLEME VE Ã–N Ä°ÅLEME
if not os.path.exists(DB_YOLU):
    print("--- Yeni VeritabanÄ± OluÅŸturuluyor ---")

    # PDF'i oku
    loader = PyPDFLoader(PDF_YOLU)
    belge = loader.load()

    # Metni parÃ§alara bÃ¶l
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=150,
        length_function=len
    )
    parcalar = text_splitter.split_documents(belge)
    print(f"PDF parÃ§alandÄ±: {len(parcalar)} adet parÃ§a oluÅŸtu.")

    # 2. VEKTÃ–RLEÅTÄ°RME VE KAYIT
    embedding_model = HuggingFaceEmbeddings(model_name="all-mpnet-base-v2")

    vector_db = Chroma.from_documents(
        documents=parcalar,
        embedding=embedding_model,
        persist_directory=DB_YOLU
    )
    print("VektÃ¶rleÅŸtirme bitti ve ChromaDB'ye kaydedildi.")

else:
    # VeritabanÄ± zaten varsa oradan oku
    print("--- Mevcut VeritabanÄ± YÃ¼kleniyor ---")
    embedding_model = HuggingFaceEmbeddings(model_name="all-mpnet-base-v2")
    vector_db = Chroma(persist_directory=DB_YOLU, embedding_function=embedding_model)


# 3. LLM AYARLARI
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.3
)


# Asistana dil kuralÄ±nÄ± burada Ã¶ÄŸretiyoruz
template = """
Sen yardÄ±msever bir asistansÄ±n. AÅŸaÄŸÄ±daki baÄŸlamÄ± (context) kullanarak soruyu cevapla.

KURALLAR:
1. EÄŸer soru TÃ¼rkÃ§e ise cevabÄ± TÃœRKÃ‡E ver.
2. EÄŸer soru Ä°ngilizce ise cevabÄ± Ä°NGÄ°LÄ°ZCE ver.
3. BaÄŸlam (context) Ä°ngilizce olsa bile, sen her zaman SORUNUN DÄ°LÄ°NDE cevap ver.

BaÄŸlam:
{context}

Soru: {question}

Cevap:
"""

prompt = ChatPromptTemplate.from_template(template)

def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

# Zinciri oluÅŸturuyoruz
rag_chain = (
    {
        "context": vector_db.as_retriever() | format_docs,
        "question": RunnablePassthrough()
    }
    | prompt
    | llm
    | StrOutputParser()
)

# --- Ã‡ALIÅTIRMA DÃ–NGÃœSÃœ ---
print("\n--- RAG AsistanÄ± HazÄ±r! (Ã‡Ä±kmak iÃ§in 'q' yazÄ±n) ---\n")

while True:
    kullanici_sorusu = input("Sorunuz: ")

    if kullanici_sorusu.lower() in ['q', 'exit', 'Ã§Ä±k']:
        print("GÃ¶rÃ¼ÅŸÃ¼rÃ¼z! ğŸ‘‹")
        break

    if not kullanici_sorusu.strip():
        continue

    print("ğŸ¤– DÃ¼ÅŸÃ¼nÃ¼yor...")

    try:
        cevap = rag_chain.invoke(kullanici_sorusu)
        print(f"\nCevap:\n{cevap}\n")
        print("-" * 50)

    except Exception as e:
        print(f"Bir hata oluÅŸtu: {e}")